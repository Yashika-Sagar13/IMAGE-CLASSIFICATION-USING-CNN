{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_pVGlar7AJX"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')[]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tviWeeHwZ8nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a046928a-3bc8-4825-d911-cf0a6b2788f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import glob\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import pathlib"
      ],
      "metadata": {
        "id": "Bnx0-g0rc8bK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Ul_T6itkdHrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkGmcA1ydVcs",
        "outputId": "5c24cf66-b8d3-4b05-eb0e-3222a9482a34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Transforms\n",
        "transformer=transforms.Compose([\n",
        "    transforms.Resize((150,150)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
        "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
        "                        [0.5,0.5,0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "8F38jigHdY_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path='/content/drive/MyDrive/Scene_detection/seg_train/seg_train'\n",
        "test_path='/content/drive/MyDrive/Scene_detection/seg_test/seg_test'\n",
        "\n",
        "train_loader=DataLoader(\n",
        "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
        "    batch_size=64, shuffle=True\n",
        ")\n",
        "test_loader=DataLoader(\n",
        "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
        "    batch_size=32, shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "c-Gpuq1zddCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root=pathlib.Path(train_path)\n",
        "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])"
      ],
      "metadata": {
        "id": "C_tL8Yaddz7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def forward(self,input):\n",
        "        output=self.conv1(input)\n",
        "        output=self.bn1(output)\n",
        "        output=self.relu1(output)\n",
        "\n",
        "        output=self.pool(output)\n",
        "\n",
        "        output=self.conv2(output)\n",
        "        output=self.relu2(output)\n",
        "\n",
        "        output=self.conv3(output)\n",
        "        output=self.bn3(output)\n",
        "        output=self.relu3(output)\n",
        "\n",
        "\n",
        "            #Above output will be in matrix form, with shape (256,32,75,75)\n",
        "\n",
        "        output=output.view(-1,32*75*75)\n",
        "\n",
        "\n",
        "        output=self.fc(output)\n",
        "\n",
        "        return output\n",
        "    def __init__(self,num_classes=6):\n",
        "        super(ConvNet,self).__init__()\n",
        "\n",
        "        #Output size after convolution filter\n",
        "        #((w-f+2P)/s) +1\n",
        "\n",
        "        #Input shape= (256,3,150,150)\n",
        "\n",
        "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (256,12,150,150)\n",
        "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
        "        #Shape= (256,12,150,150)\n",
        "        self.relu1=nn.ReLU()\n",
        "        #Shape= (256,12,150,150)\n",
        "\n",
        "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
        "        #Reduce the image size be factor 2\n",
        "        #Shape= (256,12,75,75)\n",
        "\n",
        "\n",
        "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (256,20,75,75)\n",
        "        self.relu2=nn.ReLU()\n",
        "        #Shape= (256,20,75,75)\n",
        "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (256,32,75,75)\n",
        "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
        "        #Shape= (256,32,75,75)\n",
        "        self.relu3=nn.ReLU()\n",
        "        #Shape= (256,32,75,75)\n",
        "\n",
        "\n",
        "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
        "\n"
      ],
      "metadata": {
        "id": "Hbmhofzqd39F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MwZc5EzgeADY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=ConvNet(num_classes=6).to(device)"
      ],
      "metadata": {
        "id": "cLE7D6zEeERj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
        "loss_function=nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "DqEMlMd9ePEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=10"
      ],
      "metadata": {
        "id": "jZbZFyLoeTHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_count=len(glob.glob(train_path+'/*/*.jpg'))\n",
        "test_count=len(glob.glob(test_path+'/**/*.jpg'))"
      ],
      "metadata": {
        "id": "P26a0oTSeaMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ivlsd3PSfSFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_count,test_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYAEb3JnebnI",
        "outputId": "9d89b977-3802-420b-8053-df31924c87e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14126 3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_accuracy=0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    #Evaluation and training on training dataset\n",
        "    model.train()\n",
        "    train_accuracy=0.0\n",
        "    train_loss=0.0\n",
        "    train_loss_graph=[]\n",
        "    train_accuracy_graph=[]\n",
        "\n",
        "    for i, (images,labels) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            images=Variable(images.cuda())\n",
        "            labels=Variable(labels.cuda())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs=model(images)\n",
        "        loss=loss_function(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "        train_loss+= loss.cpu().data*images.size(0)\n",
        "        _,prediction=torch.max(outputs.data,1)\n",
        "\n",
        "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "\n",
        "    train_accuracy=train_accuracy/train_count\n",
        "    train_loss=train_loss/train_count\n",
        "    train_loss_graph.append(train_loss)\n",
        "    train_accuracy_graph.append(train_accuracy)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VZ5E9MYMfTk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on testing dataset\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    test_accuracy=0.0\n",
        "    test_accuracy_graph=[]\n",
        "\n",
        "    test_loss_graph=[]\n",
        "    for i, (images,labels) in enumerate(test_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            images=Variable(images.cuda())\n",
        "            labels=Variable(labels.cuda())\n",
        "\n",
        "        outputs=model(images)\n",
        "        _,prediction=torch.max(outputs.data,1)\n",
        "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
        "\n",
        "    test_accuracy=test_accuracy/test_count\n",
        "    test_accuracy_graph.append(test_accuracy)\n",
        "    test_loss_graph.append(1-test_accuracy)\n",
        "\n",
        "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
        "\n",
        "    #Save the best model\n",
        "    if test_accuracy>best_accuracy:\n",
        "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
        "        best_accuracy=test_accuracy"
      ],
      "metadata": {
        "id": "xSH_ZN8XA2oW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "train_loss_graph.append(0.1732)\n",
        "train_loss_graph.append(0.1701)\n",
        "train_loss_graph.append(0.1756)\n",
        "train_loss_graph.append(0.1715)\n",
        "train_loss_graph.append(0.1699)\n",
        "train_loss_graph.append(0.1626)\n",
        "train_loss_graph.append(0.1786)\n",
        "train_loss_graph.append(0.1666)\n",
        "train_loss_graph.append(0.1702)\n",
        "train_loss_graph.append(0.1732)\n",
        "\n",
        "\n",
        "plt.plot(train_loss_graph)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ccYhcE3qrcc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy_graph.append( 0.9549766388220303)\n",
        "train_accuracy_graph.append( 0.9549766388220303)\n",
        "train_accuracy_graph.append( 0.9549766388220303)\n",
        "train_accuracy_graph.append( 0.9549766388220303)\n",
        "train_accuracy_graph.append( 0.9549766388220303)\n",
        "train_accuracy_graph.append( 0.9549766388220303)\n",
        "train_accuracy_graph.append( 0.9549766388220303)\n",
        "train_accuracy_graph.append( 0.9549766388220303)\n",
        "train_accuracy_graph.append( 0.9549766388220303)\n",
        "train_accuracy_graph.append( 0.9549766388220303)\n",
        "plt.plot(train_accuracy_graph)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-t9tjX7arzJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy_graph.append(0.7533333333333333)\n",
        "test_accuracy_graph.append(0.7566666666666667)\n",
        "test_accuracy_graph.append(0.756)\n",
        "test_accuracy_graph.append(0.752)\n",
        "test_accuracy_graph.append(0.7513333333333333)\n",
        "test_accuracy_graph.append(0.745)\n",
        "test_accuracy_graph.append(0.7586666666666667)\n",
        "test_accuracy_graph.append(0.753)\n",
        "test_accuracy_graph.append(0.7516666666666667)\n",
        "test_accuracy_graph.append(0.7496666666666667)\n",
        "\n",
        "plt.plot(test_accuracy_graph)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yb7JG9Imr6Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(test_loss_graph)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cr0wSFtwsAc9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}